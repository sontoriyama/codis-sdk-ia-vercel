// Demo script para mostrar las nuevas funcionalidades
// Este script demuestra cÃ³mo usar el modelo GPT-Image-1 con contexto de imagen

// Importamos las librerÃ­as necesarias (requiere npm install ai @ai-sdk/openai)
import { experimental_generateImage as generateImage } from 'ai';
import { openai } from '@ai-sdk/openai';
import { writeFile, readFile } from 'fs/promises';

async function demoContextImageGeneration() {
    console.log('ğŸ¨ === Demo: GeneraciÃ³n con Contexto de Imagen ===');
    
    try {
        // Paso 1: Generar imagen base
        console.log('\nğŸ“¸ Paso 1: Generando imagen base...');
        const baseImage = await generateImage({
            model: openai.image('gpt-image-1'),
            prompt: 'Un robot en una ciudad futurista, estilo cyberpunk, colores neÃ³n',
            size: '1024x1024'
        });
        
        console.log('âœ… Imagen base generada');
        await writeFile('demo-base.png', baseImage.uint8Array);
        console.log('ğŸ’¾ Guardada como: demo-base.png');
        
        // Paso 2: Usar la imagen como contexto para una variaciÃ³n
        console.log('\nğŸ”„ Paso 2: Generando variaciÃ³n con contexto...');
        
        // Nota: En la implementaciÃ³n real, necesitarÃ­as convertir la imagen a base64
        // y usar la nueva funcionalidad de contexto cuando estÃ© disponible en la API
        
        const variationImage = await generateImage({
            model: openai.image('gpt-image-1'),
            prompt: 'El mismo robot pero ahora volando entre los edificios, con efectos de movimiento',
            size: '1024x1024',
            // context_image: base64Image // Funcionalidad futura
        });
        
        console.log('âœ… VariaciÃ³n generada');
        await writeFile('demo-variation.png', variationImage.uint8Array);
        console.log('ğŸ’¾ Guardada como: demo-variation.png');
        
        // Paso 3: Demostrar diferentes modelos
        console.log('\nğŸ¤– Paso 3: Comparando modelos...');
        
        const models = [
            { name: 'GPT-Image-1', model: 'gpt-image-1' },
            { name: 'DALL-E 3', model: 'dall-e-3' },
            { name: 'DALL-E 2', model: 'dall-e-2' }
        ];
        
        for (const modelInfo of models) {
            console.log(`\nğŸ¯ Generando con ${modelInfo.name}...`);
            
            const testImage = await generateImage({
                model: openai.image(modelInfo.model),
                prompt: 'Un gato mÃ¡gico con poderes elementales, arte digital',
                size: '1024x1024'
            });
            
            const filename = `demo-${modelInfo.model.replace('-', '')}.png`;
            await writeFile(filename, testImage.uint8Array);
            console.log(`âœ… ${modelInfo.name} completado - ${filename}`);
        }
        
        console.log('\nğŸ‰ Demo completado exitosamente!');
        console.log('\nğŸ“ Archivos generados:');
        console.log('  - demo-base.png (imagen base)');
        console.log('  - demo-variation.png (variaciÃ³n)');
        console.log('  - demo-gptimage1.png (GPT-Image-1)');
        console.log('  - demo-dalle3.png (DALL-E 3)');
        console.log('  - demo-dalle2.png (DALL-E 2)');
        
    } catch (error) {
        console.error('âŒ Error durante la demo:', error);
        console.log('\nğŸ’¡ Consejos:');
        console.log('  - Verifica que tengas una API key vÃ¡lida');
        console.log('  - AsegÃºrate de tener crÃ©ditos suficientes');
        console.log('  - Comprueba tu conexiÃ³n a internet');
    }
}

// FunciÃ³n para demostrar la conversiÃ³n a base64 (para contexto futuro)
async function demoBase64Conversion() {
    console.log('\nğŸ”§ === Demo: ConversiÃ³n a Base64 para Contexto ===');
    
    try {
        // Leer una imagen existente y convertirla a base64
        const imageBuffer = await readFile('demo-base.png');
        const base64Image = imageBuffer.toString('base64');
        const dataUrl = `data:image/png;base64,${base64Image}`;
        
        console.log('âœ… Imagen convertida a base64');
        console.log(`ğŸ“ TamaÃ±o: ${Math.round(base64Image.length / 1024)} KB`);
        console.log(`ğŸ”— Data URL: ${dataUrl.substring(0, 50)}...`);
        
        // Guardar el base64 para referencia
        await writeFile('demo-base64.txt', dataUrl);
        console.log('ğŸ’¾ Base64 guardado en: demo-base64.txt');
        
    } catch (error) {
        console.error('âŒ Error en conversiÃ³n base64:', error);
    }
}

// FunciÃ³n principal
async function main() {
    console.log('ğŸš€ Iniciando demo de funcionalidades avanzadas...');
    console.log('âš¡ Usando GPT-Image-1 con contexto de imagen');
    console.log('ğŸ“… Fecha:', new Date().toISOString());
    
    await demoContextImageGeneration();
    await demoBase64Conversion();
    
    console.log('\nğŸ¯ La UI web ahora incluye:');
    console.log('  âœ… SelecciÃ³n de modelo (GPT-Image-1, DALL-E 3, DALL-E 2)');
    console.log('  âœ… Carga de imagen de contexto');
    console.log('  âœ… Vista previa de contexto');
    console.log('  âœ… BotÃ³n "Usar como contexto"');
    console.log('  âœ… Interfaz mejorada y responsiva');
    
    console.log('\nğŸŒŸ Â¡Abre ui.html para probar la nueva interfaz!');
}

// Ejecutar demo
main().catch(console.error);
